{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from numpy import fft\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_harmonics_function(data_stock):\n",
    "    harmonics = {}\n",
    "    for i in data_stock:\n",
    "        harmonics[i] = {}\n",
    "        # get data_stock's infomation\n",
    "        data = data_stock[i]['Close']\n",
    "        array_data = np.array(data)\n",
    "        n_data = array_data.size\n",
    "        time_data = np.arange(0, n_data)\n",
    "\n",
    "        # detrend data\n",
    "        # find linear trend in data\n",
    "        Polynomial = np.polyfit(time_data, array_data, 1)\n",
    "        data_notrend = array_data - Polynomial[0] * time_data    # detrended x\n",
    "\n",
    "        # fft process\n",
    "        data_freqdom = fft.fft(data_notrend, n=n_data)\n",
    "        frequence = fft.fftfreq(n_data)\n",
    "        f_positive = frequence[np.where(frequence > 0)]\n",
    "        data_freqdom_positive = data_freqdom[np.where(frequence > 0)]\n",
    "\n",
    "        # sort indexes\n",
    "        indexes = list(range(f_positive.size))      # frequencies\n",
    "        # sort method 1\n",
    "        # indexes.sort(key = lambda i: np.absolute(frequence[i]))     # sort indexes by frequency, lower -> higher\n",
    "        # sort method 2 :\n",
    "        # sort indexes by amplitudes, lower -> higher\n",
    "        indexes.sort(key=lambda i: np.absolute(data_freqdom[i]))\n",
    "        indexes.reverse()       # sort indexes by amplitudes, higher -> lower\n",
    "\n",
    "        # get data_all_time'size\n",
    "        time_transfer = np.arange(0, 2*array_data.size)\n",
    "\n",
    "        # mix harmonics\n",
    "        for j in indexes:\n",
    "            ampli = np.absolute(\n",
    "                data_freqdom_positive[j]) / n_data     # amplitude\n",
    "            phase = np.angle(data_freqdom_positive[j])      # phase\n",
    "            harmonics[i][j] = ampli * \\\n",
    "                np.cos(2 * np.pi * f_positive[j] * time_transfer + phase)\n",
    "    return harmonics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pv_function(data, pv_range):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    try:\n",
    "        for i in data:\n",
    "            pv = data[i]['Close']\n",
    "            data[i]['peaks'] = pd.Series(dtype='float64')\n",
    "            data[i]['valleys'] = pd.Series(dtype='float64')\n",
    "            peaks = data[i]['peaks']\n",
    "            valleys = data[i]['valleys']\n",
    "            for idx in range(0, len(pv)):\n",
    "                if idx < pv_range:\n",
    "                    if pv[idx] == pv.iloc[0:pv_range*2+1].max():\n",
    "                        peaks.iloc[idx] = pv[idx]\n",
    "                    if pv[idx] == pv.iloc[0:pv_range*2+1].min():\n",
    "                        valleys.iloc[idx] = pv[idx]\n",
    "                if pv[idx] == pv.iloc[idx-pv_range:idx+pv_range].max():\n",
    "                    peaks.iloc[idx] = pv[idx]\n",
    "                if pv[idx] == pv.iloc[idx-pv_range:idx+pv_range].min():\n",
    "                    valleys.iloc[idx] = pv[idx]\n",
    "            data[i]['peaks'] = peaks\n",
    "            data[i]['valleys'] = valleys\n",
    "    except:\n",
    "        for i in data:\n",
    "            for j in data[i]:\n",
    "                pv = data[i][j]['Close']\n",
    "                data[i][j]['peaks'] = pd.Series(dtype='float64')\n",
    "                data[i][j]['valleys'] = pd.Series(dtype='float64')\n",
    "                peaks = data[i][j]['peaks']\n",
    "                valleys = data[i][j]['valleys']\n",
    "                for idx in range(0, len(pv)):\n",
    "                    if idx < pv_range:\n",
    "                        if pv[idx] == pv.iloc[0:pv_range*2+1].max():\n",
    "                            peaks.iloc[idx] = pv[idx]\n",
    "                        if pv[idx] == pv.iloc[0:pv_range*2+1].min():\n",
    "                            valleys.iloc[idx] = pv[idx]\n",
    "                    if pv[idx] == pv.iloc[idx-pv_range:idx+pv_range].max():\n",
    "                        peaks.iloc[idx] = pv[idx]\n",
    "                    if pv[idx] == pv.iloc[idx-pv_range:idx+pv_range].min():\n",
    "                        valleys.iloc[idx] = pv[idx]\n",
    "                data[i][j]['peaks'] = peaks\n",
    "                data[i][j]['valleys'] = valleys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_harmonics(harmonics, n_harm_lower_limit, n_harm_upper_limit):\n",
    "    processed_signal = {}\n",
    "    for i in harmonics:\n",
    "        processed_signal[i] = {}\n",
    "        for n_harm in range(n_harm_lower_limit, n_harm_upper_limit+1):\n",
    "            mixed_harmonic = np.zeros(len(harmonics[i][0]))\n",
    "            for j in range(n_harm):\n",
    "                mixed_harmonic += harmonics[i][j]\n",
    "                # print(n_harm)\n",
    "            cuted_mixed_harmonic = mixed_harmonic[int(\n",
    "                len(mixed_harmonic)/2):int(len(mixed_harmonic))]\n",
    "            processed_signal[i][n_harm] = pd.DataFrame(\n",
    "                {'Close': cuted_mixed_harmonic})\n",
    "    return processed_signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pv_lead_function(data, processed_signal):\n",
    "    for d in data:\n",
    "        for p in processed_signal[d]:\n",
    "            processed_signal[d][p]['pv'] = pd.Series(dtype='str')\n",
    "            # print(data[d])\n",
    "            processing_signal = processed_signal[d][p].loc[list(data[d].index)]\n",
    "            p_data = pd.DataFrame(\n",
    "                {'peaks': data[d]['peaks'], 'count': range(len(data[d]))})\n",
    "            p_data = p_data.drop(p_data[p_data['peaks'].isna()].index)\n",
    "            p_data_count = list(p_data['count'])\n",
    "            p_signal = pd.DataFrame(\n",
    "                {'peaks': processing_signal['peaks'], 'count': range(len(processing_signal))})\n",
    "            p_signal = p_signal.drop(p_signal[p_signal['peaks'].isna()].index)\n",
    "            p_signal_list = list(p_signal['count'])\n",
    "            p_lead = []\n",
    "            for i in range(0, len(p_signal_list)):\n",
    "                temp = []\n",
    "                temp_abs = []\n",
    "                temp_2 = []\n",
    "                for j in range(0, len(p_data_count)):\n",
    "                    temp.append((p_data_count[j] - p_signal_list[i]))\n",
    "                    temp_abs.append(abs(p_data_count[j] - p_signal_list[i]))\n",
    "                for k in range(0, len(temp_abs)):\n",
    "                    if temp_abs[k] == min(temp_abs):\n",
    "                        temp_2 = temp[k]\n",
    "                p_lead.append(temp_2)\n",
    "            p_signal['lead'] = p_lead\n",
    "            processed_signal[d][p]['lead'] = pd.Series(dtype='float64')\n",
    "            processed_signal[d][p]['lead'].loc[p_signal['lead'].index] = p_signal['lead']\n",
    "            processed_signal[d][p]['pv'].loc[p_signal['lead'].index] = 'peak'\n",
    "\n",
    "            v_data = pd.DataFrame(\n",
    "                {'valleys': data[d]['valleys'], 'count': range(len(data[d]))})\n",
    "            v_data = v_data.drop(v_data[v_data['valleys'].isna()].index)\n",
    "            v_data_count = list(v_data['count'])\n",
    "            v_signal = pd.DataFrame(\n",
    "                {'valleys': processing_signal['valleys'], 'count': range(len(processing_signal))})\n",
    "            v_signal = v_signal.drop(\n",
    "                v_signal[v_signal['valleys'].isna()].index)\n",
    "            v_signal_list = list(v_signal['count'])\n",
    "            v_lead = []\n",
    "            for i in range(0, len(v_signal_list)):\n",
    "                temp = []\n",
    "                temp_abs = []\n",
    "                temp_2 = []\n",
    "                for j in range(0, len(v_data_count)):\n",
    "                    temp.append((v_data_count[j] - v_signal_list[i]))\n",
    "                    # print(v_data_count[j])\n",
    "                    # print(v_signal_list[i])\n",
    "                    temp_abs.append(abs(v_data_count[j] - v_signal_list[i]))\n",
    "                for k in range(0, len(temp_abs)):\n",
    "                    if temp_abs[k] == min(temp_abs):\n",
    "                        temp_2 = temp[k]\n",
    "                v_lead.append(temp_2)\n",
    "            v_signal['lead'] = v_lead\n",
    "            processed_signal[d][p]['lead'].loc[v_signal['lead'].index] = v_signal['lead']\n",
    "            processed_signal[d][p]['pv'].loc[v_signal['lead'].index] = 'valley'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fit_error_function(processed_signal, fit_method):\n",
    "    errors = {}\n",
    "    for i in processed_signal:\n",
    "        errors[i] = {}\n",
    "        for j in processed_signal[i]:\n",
    "            signal_dropna = processed_signal[i][j].drop(\n",
    "                processed_signal[i][j][processed_signal[i][j]['lead'].isna()].index)\n",
    "            if fit_method == 'mean':\n",
    "                error = signal_dropna['lead'].mean()\n",
    "            elif fit_method == 'abs':\n",
    "                error = abs(signal_dropna['lead']).mean()\n",
    "            errors[i][j] = error\n",
    "    return errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_error_task(processed_signal, errors):\n",
    "    best_error = {}\n",
    "    best_fit_harm = {}\n",
    "    for i in processed_signal:\n",
    "        best_error[i] = pd.Series(errors[i]).abs().min()\n",
    "        best_fit_harm[i] = pd.Series(errors[i]).abs().idxmin()\n",
    "        # print(best_fit_harm, best_error)\n",
    "    return best_fit_harm, best_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_lead_function(processed_signal):\n",
    "    first_date = {}\n",
    "    lead = {}\n",
    "    pv = {}\n",
    "    for i in processed_signal:\n",
    "        first_date[i] = {}\n",
    "        lead[i] = {}\n",
    "        pv[i] = {}\n",
    "        for j in processed_signal[i]:\n",
    "            temp = processed_signal[i][j].loc[list(\n",
    "                processed_signal[i][j]['lead'].dropna().index)[0]]\n",
    "            first_date[i][j] = list(\n",
    "                processed_signal[i][j]['lead'].dropna().index)[0]\n",
    "            lead[i][j] = temp['lead']\n",
    "            pv[i][j] = temp['pv']\n",
    "    return first_date, lead, pv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_lead_function_best_fit(processed_signal, best_fit_harm):\n",
    "    first_date = {}\n",
    "    lead = {}\n",
    "    pv = {}\n",
    "    for i in processed_signal:\n",
    "        harm = best_fit_harm[i]\n",
    "        temp = processed_signal[i][harm].loc[list(\n",
    "            processed_signal[i][harm]['lead'].dropna().index)[0]]\n",
    "        first_date[i] = list(processed_signal[i][harm]\n",
    "                             ['lead'].dropna().index)[0]\n",
    "        lead[i] = temp['lead']\n",
    "        pv[i] = temp['pv']\n",
    "    return first_date, lead, pv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stock_name, date_predict_start, data_range, slide_range, n_slide):\n",
    "    train_data = {}\n",
    "    test_data = {}\n",
    "    date_predict_start = datetime.datetime.strptime(\n",
    "        date_predict_start, '%Y-%m-%d')\n",
    "    date_data_start_list = []\n",
    "    date_predict_start_list = []\n",
    "    date_predict_end_list = []\n",
    "    for i in range(n_slide*2):\n",
    "        date_data_start = date_predict_start - \\\n",
    "            relativedelta(days=+data_range)\n",
    "        date_predict_end = date_predict_start + \\\n",
    "            relativedelta(days=+data_range)\n",
    "        date_data_start_list.append(date_data_start)\n",
    "        date_predict_start_list.append(date_predict_start)\n",
    "        date_predict_end_list.append(date_predict_end)\n",
    "        date_data_start = date_data_start + \\\n",
    "            relativedelta(days=+slide_range)\n",
    "        date_predict_start = date_predict_start + \\\n",
    "            relativedelta(days=+slide_range)\n",
    "\n",
    "    train_data_all = yf.Ticker(stock_name).history(\n",
    "        start=date_data_start_list[0], end=date_predict_start_list[-1])\n",
    "    test_data_all = yf.Ticker(stock_name).history(\n",
    "        start=date_predict_start_list[0], end=date_predict_end_list[-1])\n",
    "    test_data_all['count'] = range(len(test_data_all))\n",
    "    test_data_start_list = []\n",
    "    for i in range(n_slide):\n",
    "        train_data['data_' + str(i)] = train_data_all.iloc[i *\n",
    "                                                           slide_range:i*slide_range+data_range]\n",
    "        train_data['data_' + str(i)] = train_data['data_' +\n",
    "                                                  str(i)].reset_index(drop=True)\n",
    "        test_data['data_' + str(i)] = test_data_all.iloc[i *\n",
    "                                                         slide_range:i*slide_range+data_range]\n",
    "        test_data_start_list.append(test_data['data_' + str(i)].index[0])\n",
    "        test_data['data_' + str(i)] = test_data['data_' +\n",
    "                                                str(i)].reset_index(drop=True)\n",
    "    return train_data, test_data, test_data_all, test_data_start_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(processed_signal, fit_method):\n",
    "    errors = get_fit_error_function(processed_signal, fit_method)\n",
    "    best_fit_harm, best_error = fit_error_task(processed_signal, errors)\n",
    "    first_date, lead, pv = get_first_lead_function_best_fit(\n",
    "        processed_signal, best_fit_harm)\n",
    "    return best_fit_harm, best_error, first_date, lead, pv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(processed_signal, test_data_start_list, test_data_all, best_fit_harm, best_error, first_date, lead, pv):\n",
    "    result_table = pd.DataFrame(columns=[\n",
    "        'start_date', 'target_date_after_start', 'target_date', 'lead', 'pv', 'error', 'best_fit'])\n",
    "    for i in processed_signal:\n",
    "        result_table.loc[i, 'error'] = round(best_error[i], 2)\n",
    "        result_table.loc[i, 'best_fit'] = best_fit_harm[i]\n",
    "        result_table.loc[i, 'target_date_after_start'] = first_date[i]\n",
    "        result_table.loc[i, 'lead'] = lead[i]\n",
    "        result_table.loc[i, 'pv'] = pv[i]\n",
    "    result_table['start_date'] = test_data_start_list\n",
    "    for i in result_table.index:\n",
    "        target_date = test_data_all.loc[test_data_all['count'] ==\n",
    "                                        test_data_all['count'].loc[result_table.loc[i, 'start_date']] +\n",
    "                                        result_table.loc[i, 'target_date_after_start']].index[0]\n",
    "        target_date = datetime.datetime.strftime(target_date, '%Y-%m-%d')\n",
    "        result_table.loc[i, 'target_date'] = target_date\n",
    "    final_error = round(\n",
    "        sum([abs(ele) for ele in result_table['lead']]) / len(result_table['lead']), 2)\n",
    "    return result_table, final_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_funtion(\n",
    "    stock_name, date_predict_start, data_range, slide_range,\n",
    "        n_slide, pv_range, n_harm_lower_limit, n_harm_upper_limit, fit_method):\n",
    "\n",
    "    # 1. Load data\n",
    "    train_data, test_data, test_data_all, test_data_start_list = load_data(\n",
    "        stock_name, date_predict_start, data_range, slide_range, n_slide)\n",
    "    # 2. Preprocessing\n",
    "    find_pv_function(train_data, pv_range)\n",
    "    find_pv_function(test_data, pv_range)\n",
    "    # 3. Build model\n",
    "    harmonics = data_to_harmonics_function(train_data)\n",
    "    processed_signal = mix_harmonics(\n",
    "        harmonics, n_harm_lower_limit, n_harm_upper_limit)\n",
    "    find_pv_function(processed_signal, pv_range)\n",
    "    find_pv_lead_function(test_data, processed_signal)\n",
    "    # 4. Train model\n",
    "    best_fit_harm, best_error, first_date, lead, pv = train_model(\n",
    "        processed_signal, fit_method)\n",
    "    # 5. Evaluate model\n",
    "    result_table, final_error = evaluate_model(\n",
    "        processed_signal, test_data_start_list, test_data_all, best_fit_harm, best_error, first_date, lead, pv)\n",
    "    print('final_error = ', final_error)\n",
    "    print(result_table)\n",
    "    # 6. Predict\n",
    "\n",
    "    # return result_table, final_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_name = \"^GSPC\"\n",
    "# date_predict_start = '2021-01-01'\n",
    "# data_range = 200\n",
    "# slide_range = 10\n",
    "# n_slide = 24\n",
    "# pv_range = 2\n",
    "# n_harm_lower_limit = 20\n",
    "# n_harm_upper_limit = 40\n",
    "# fit_method = 'mean'\n",
    "# train_data = {}\n",
    "# test_data = {}\n",
    "# date_predict_start = datetime.datetime.strptime(\n",
    "#     date_predict_start, '%Y-%m-%d')  # ex.'2021-01-01'\n",
    "# date_data_start_list = []\n",
    "# date_predict_start_list = []\n",
    "# date_predict_end_list = []\n",
    "# for i in range(n_slide*2):\n",
    "#     date_data_start = date_predict_start - \\\n",
    "#         relativedelta(days=+data_range)  # ex.'2020-07-01'\n",
    "#     date_predict_end = date_predict_start + \\\n",
    "#         relativedelta(days=+data_range)  # ex.'2021-07-01'\n",
    "#     date_data_start_list.append(date_data_start)\n",
    "#     date_predict_start_list.append(date_predict_start)\n",
    "#     date_predict_end_list.append(date_predict_end)\n",
    "#     date_data_start = date_data_start + \\\n",
    "#         relativedelta(days=+slide_range)  # ex.'2020-07-15'\n",
    "#     date_predict_start = date_predict_start + \\\n",
    "#         relativedelta(days=+slide_range)  # ex.'2021-01-15'\n",
    "\n",
    "# train_data_all = yf.Ticker(stock_name).history(\n",
    "#     start=date_data_start_list[0], end=date_predict_start_list[-1])\n",
    "# test_data_all = yf.Ticker(stock_name).history(\n",
    "#     start=date_predict_start_list[0], end=date_predict_end_list[-1])\n",
    "# test_data_all['count'] = range(len(test_data_all))\n",
    "# test_data_start_list = []\n",
    "# for i in range(n_slide):\n",
    "#     train_data['data_' + str(i)] = train_data_all.iloc[i *\n",
    "#                                                        slide_range:i*slide_range+data_range]\n",
    "#     train_data['data_' + str(i)] = train_data['data_' +\n",
    "#                                               str(i)].reset_index(drop=True)\n",
    "#     test_data['data_' + str(i)] = test_data_all.iloc[i *\n",
    "#                                                      slide_range:i*slide_range+data_range]\n",
    "#     test_data_start_list.append(test_data['data_' + str(i)].index[0])\n",
    "#     test_data['data_' + str(i)] = test_data['data_' +\n",
    "#                                             str(i)].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_error =  1.42\n",
      "        start_date target_date_after_start target_date lead      pv error  \\\n",
      "data_0  2020-12-31                       0  2020-12-31  1.0  valley  0.03   \n",
      "data_1  2021-01-15                       1  2021-01-19 -1.0  valley  0.02   \n",
      "data_2  2021-02-01                       2  2021-02-03 -2.0  valley  0.05   \n",
      "data_3  2021-02-16                       0  2021-02-16  4.0  valley  0.03   \n",
      "data_4  2021-03-02                       0  2021-03-02  2.0  valley   0.0   \n",
      "data_5  2021-03-16                       0  2021-03-16  3.0  valley   0.0   \n",
      "data_6  2021-03-30                       0  2021-03-30  0.0  valley   0.0   \n",
      "data_7  2021-04-14                       1  2021-04-15 -1.0  valley  0.02   \n",
      "data_8  2021-04-28                       0  2021-04-28  2.0  valley  0.03   \n",
      "data_9  2021-05-12                       0  2021-05-12  2.0    peak   0.0   \n",
      "data_10 2021-05-26                       0  2021-05-26  0.0  valley  0.03   \n",
      "data_11 2021-06-10                       0  2021-06-10  2.0    peak  0.03   \n",
      "data_12 2021-06-24                       0  2021-06-24  0.0  valley  0.03   \n",
      "data_13 2021-07-09                       0  2021-07-09  2.0  valley   0.0   \n",
      "data_14 2021-07-23                       0  2021-07-23  3.0  valley   0.0   \n",
      "data_15 2021-08-06                       1  2021-08-09  0.0  valley  0.02   \n",
      "data_16 2021-08-20                       1  2021-08-23 -1.0  valley  0.02   \n",
      "data_17 2021-09-03                       2  2021-09-08 -2.0    peak  0.02   \n",
      "data_18 2021-09-20                       2  2021-09-22 -1.0  valley   0.0   \n",
      "data_19 2021-10-04                       0  2021-10-04  3.0    peak  0.04   \n",
      "data_20 2021-10-18                       1  2021-10-19 -1.0  valley  0.07   \n",
      "data_21 2021-11-01                       0  2021-11-01  0.0  valley  0.12   \n",
      "data_22 2021-11-15                       0  2021-11-15  0.0  valley  0.03   \n",
      "data_23 2021-11-30                       0  2021-11-30  1.0  valley  0.04   \n",
      "\n",
      "        best_fit  \n",
      "data_0        25  \n",
      "data_1        38  \n",
      "data_2        31  \n",
      "data_3        21  \n",
      "data_4        22  \n",
      "data_5        21  \n",
      "data_6        22  \n",
      "data_7        38  \n",
      "data_8        23  \n",
      "data_9        37  \n",
      "data_10       25  \n",
      "data_11       21  \n",
      "data_12       21  \n",
      "data_13       23  \n",
      "data_14       20  \n",
      "data_15       38  \n",
      "data_16       38  \n",
      "data_17       38  \n",
      "data_18       27  \n",
      "data_19       36  \n",
      "data_20       38  \n",
      "data_21       38  \n",
      "data_22       27  \n",
      "data_23       40  \n"
     ]
    }
   ],
   "source": [
    "stock_name = \"^GSPC\"\n",
    "date_predict_start = '2021-01-01'\n",
    "data_range = 200\n",
    "slide_range = 10\n",
    "n_slide = 24\n",
    "pv_range = 2\n",
    "n_harm_lower_limit = 20\n",
    "n_harm_upper_limit = 40\n",
    "fit_method = 'mean'\n",
    "main_funtion(\n",
    "    stock_name, date_predict_start, data_range, slide_range,\n",
    "    n_slide, pv_range, n_harm_lower_limit, n_harm_upper_limit, fit_method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv_stock': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba787645ba8ce3b43ca5d5c1bc5ea17dd580ada22e1bd31731a2a86b718f16cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
